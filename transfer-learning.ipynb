{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pendahuluan\n",
    "\n",
    "[Keras](https://github.com/keras-team/keras/blob/master/README.md) memiliki banyak model *deep learning* untuk klasifikasi gambar yang siap pakai. Dengan mengatur parameter ``weights='imagenet'``, *weight* hasil *training* berhari-hari pada jutaan gambar dari dataset ImageNet otomatis di*download*. Tanpa kita *training* di PC sendiri, model dapat kita masukkan gambar sembarang untuk diklasifikasi.\n",
    "\n",
    "Jumlah kelas dataset ImageNet sangat banyak, ada 1000. Perhatikan sampel berikut. \n",
    "\n",
    ">#### ImageNet [classes.txt](https://github.com/xmartlabs/caffeflow/blob/master/examples/imagenet/imagenet-classes.txt)\n",
    ">... head cabbage broccoli cauliflower zucchini, courgette spaghetti squash acorn squash butternut squash cucumber, cuke artichoke, globe artichoke bell pepper cardoon mushroom Granny Smith strawberry orange lemon fig pineapple, ananas **banana** jackfruit, jak, jack custard apple pomegranate ...\n",
    "\n",
    "Model mampu membedakan berbagai sayur dan buah. Akan tetapi, model tidak cukup spesifik untuk membedakan varian dari setiap sayur atau buah dalam perbendaharaannya. Model akan memprediksi, misalnya, 'orange' ketika dimasukkan gambar jeruk mandarin maupun jeruk sunkist. Pada artikel ini kita akan membuat model yang khusus membedakan antara **pisang tanduk** dan **pisang kepok**. Kita akan menggunakan salah satu model yang disediakan Keras, DenseNet121."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet\n",
    "\n",
    "DenseNet models {121, 169, 201}, with weights pre-trained on ImageNet.\n",
    "\n",
    "This model and can be built both with 'channels_first' data format (channels, height, width) or 'channels_last' data format (height, width, channels).\n",
    "\n",
    "The default input size for this model is 224x224.\n",
    "\n",
    "```\n",
    "keras.applications.densenet.DenseNet121(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "\n",
    "```\n",
    "\n",
    "#### Arguments\n",
    "+ blocks: numbers of building blocks for the four dense layers.\n",
    "+ include_top: whether to include the fully-connected layer at the top of the network.\n",
    "+ weights: one of None (random initialization), 'imagenet' (pre-training on ImageNet), or the path to the weights file to be loaded.\n",
    "+ input_tensor: optional Keras tensor (i.e. output of layers.Input()) to use as image input for the model.\n",
    "+ input_shape: optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with 'channels_last' data format) or (3, 224, 224) (with 'channels_first' data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.\n",
    "+ pooling: optional pooling mode for feature extraction when include_top is False. None means that the output of the model will be the 4D tensor output of the last convolutional layer. avg means that global average pooling will be applied to the output of the last convolutional layer, and thus the output of the model will be a 2D tensor. max means that global max pooling will be applied.\n",
    "+ classes: optional number of classes to classify images into, only to be specified if include_top is True, and if no weights argument is specified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Import secukupnya :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import densenet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.densenet import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengumpulkan Gambar Pisang\n",
    "\n",
    "Dataset khusus gambar pisang tanduk maupun pisang kepok agak sulit untuk ditemukan. Untungnya kita hanya memerlukan sedikit data untuk *transfer learning*, sehingga untuk mencari di Google Image lima puluh gambar pisang rasanya masih manusiawi. Untuk sedikit meringankan pekerjaan (kita harus memverifikasi hasil download secara manual), kita gunakan [google-image-download](https://github.com/hardikvasa/google-images-download).\n",
    "\n",
    "Simpan gambar-gambar pisang sehingga struktur folder kita menjadi seperti berikut (andaikan kita punya 50 gambar pisang kepok dan 50 pisang tanduk.\n",
    "\n",
    "    pisang-train/\n",
    "        pisang-kepok/\n",
    "            kepok-pisang(1).jpg\n",
    "            ...\n",
    "            kepok-manis(45).jpg        \n",
    "        pisang-tanduk/\n",
    "            pisang-tanduk(1).jpg\n",
    "            ...\n",
    "            tanduk(45).jpg\n",
    "    pisang-test/\n",
    "        kepok001.jpg\n",
    "        kepok002.jpg\n",
    "        ...\n",
    "        kepok005.jpg\n",
    "        tanduk001.jpg\n",
    "        tanduk002.jpg\n",
    "        ...\n",
    "        tanduk005.jpg\n",
    "\n",
    "Catatan: penamaan data *train* bebas, sedangkan nama file data *test* sebaiknya mengandung kelasnya untuk mempermudah membaca hasil prediksi nanti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n",
      "{'pisang-kepok': 0, 'pisang-tanduk': 1}\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory('pisang-train/', \n",
    "                                                    target_size=(224,224), \n",
    "                                                    color_mode='rgb', \n",
    "                                                    batch_size=32, \n",
    "                                                    class_mode='categorical', \n",
    "                                                    shuffle=True)\n",
    "category_dict = train_generator.class_indices\n",
    "print(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(category_dict)\n",
    "\n",
    "base_model = densenet.DenseNet121(weights='densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5', \n",
    "                                  include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "preds = Dense(number_of_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "\n",
    "# Print the updated layer names.\n",
    "# for i,layer in enumerate(model.layers): print(i,layer.name)\n",
    "\n",
    "# Set the first n_freeze layers of the network to be non-trainable.\n",
    "n_freeze = 300\n",
    "for layer in model.layers[:n_freeze]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[n_freeze:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catatan: Jumlah layer dapat diketahui dengan ```print(len(model.layers))```. \n",
    "\n",
    "Perintah terakhir mengatur supaya 300 layer pertama di*freeze*, yakni hanya layer ke 301 sampai layer sebelum *output* saja yang di*train* parameternya. Jika mau, kita juga dapat mengatur supaya hanya layer *output* saja yang di*train* (murni *transfer learning*) seperti berikut.\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 24s 8s/step - loss: 1.0033 - acc: 0.5833\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 13s 4s/step - loss: 0.6711 - acc: 0.7096\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 13s 4s/step - loss: 0.3510 - acc: 0.8534\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 0.1326 - acc: 0.9426\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 18s 6s/step - loss: 0.0367 - acc: 0.9896\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 13s 4s/step - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 12s 4s/step - loss: 0.0620 - acc: 0.9770\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 17s 6s/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 13s 4s/step - loss: 0.0116 - acc: 0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11b5b34f60>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "step_size_train = train_generator.n//train_generator.batch_size\n",
    "model.fit_generator(generator=train_generator, \n",
    "                    steps_per_epoch=step_size_train, \n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without transfer learning.\n",
    "default_model = densenet.DenseNet121(weights='densenet121_weights_tf_dim_ordering_tf_kernels.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```decode_predictions``` dapat digunakan untuk membuat keluaran model (*array* 1000 kelas) menjadi *human-readable*.\n",
    "```\n",
    "prediction = model.predict(x)\n",
    "keras.applications.densenet.decode_predictions(prediction, top=2)\n",
    "```\n",
    "Kebutuhan pengujian model kita dapat diimplementasi dengan *get key by value in dictionary*. (Saya kesulitan mencari *method* serupa yang lebih generik, yakni dapat digunakan untuk *transfer learning* dengan jumlah kelas ≠ 1000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Transfer Learning Top-2 [kepok008.jpg]: \n",
      "[('n07753592', 'banana', 0.50477576), ('n07760859', 'custard_apple', 0.301058)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok008.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "pisang-tanduk (1.496673784906477e-07%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [tanduk006.jpg]: \n",
      "[('n04136333', 'sarong', 0.24845652), ('n04417672', 'thatch', 0.21268867)]\n",
      "\n",
      "\n",
      "With Transfer Learning [tanduk006.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-tanduk (99.99977350234985%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (0.0002311575144631206%)\n",
      "pisang-tanduk (99.99977350234985%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok015.jpg]: \n",
      "[('n03388043', 'fountain', 0.15597062), ('n07753592', 'banana', 0.104576446)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok015.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-tanduk (56.99564218521118%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (43.004366755485535%)\n",
      "pisang-tanduk (56.99564218521118%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok016.jpg]: \n",
      "[('n07753592', 'banana', 0.85136515), ('n07716906', 'spaghetti_squash', 0.10280364)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok016.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (98.98748397827148%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (98.98748397827148%)\n",
      "pisang-tanduk (1.012518722563982%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok024.jpg]: \n",
      "[('n03594734', 'jean', 0.046161953), ('n04235860', 'sleeping_bag', 0.04285508)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok024.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (99.99998807907104%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (99.99998807907104%)\n",
      "pisang-tanduk (9.681986057330505e-06%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok018.jpg]: \n",
      "[('n07753592', 'banana', 0.52466184), ('n11939491', 'daisy', 0.10875565)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok018.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "pisang-tanduk (1.2517317737881228e-08%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok003.jpg]: \n",
      "[('n07753592', 'banana', 0.9254071), ('n07716906', 'spaghetti_squash', 0.032233566)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok003.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (99.92074370384216%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (99.92074370384216%)\n",
      "pisang-tanduk (0.0792567094322294%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok011.jpg]: \n",
      "[('n07753592', 'banana', 0.99775875), ('n07760859', 'custard_apple', 0.0005987311)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok011.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "pisang-tanduk (2.0862025214979374e-10%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [tanduk007.jpg]: \n",
      "[('n07753592', 'banana', 0.17596042), ('n02281406', 'sulphur_butterfly', 0.14723785)]\n",
      "\n",
      "\n",
      "With Transfer Learning [tanduk007.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-tanduk (99.90654587745667%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (0.09346090955659747%)\n",
      "pisang-tanduk (99.90654587745667%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [tanduk005.jpg]: \n",
      "[('n07753592', 'banana', 0.99778193), ('n01749939', 'green_mamba', 0.00032038917)]\n",
      "\n",
      "\n",
      "With Transfer Learning [tanduk005.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-tanduk (100.0%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (4.324075320027987e-07%)\n",
      "pisang-tanduk (100.0%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [tanduk002.jpg]: \n",
      "[('n07753592', 'banana', 0.96456325), ('n07747607', 'orange', 0.005010759)]\n",
      "\n",
      "\n",
      "With Transfer Learning [tanduk002.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-tanduk (99.99759197235107%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (0.0024084756660158746%)\n",
      "pisang-tanduk (99.99759197235107%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok001.jpg]: \n",
      "[('n07753592', 'banana', 0.946655), ('n07754684', 'jackfruit', 0.011156842)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok001.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "pisang-tanduk (2.0647352272362696e-06%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok019.jpg]: \n",
      "[('n07753592', 'banana', 0.2179696), ('n03991062', 'pot', 0.18494076)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok019.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (99.97817873954773%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (99.97817873954773%)\n",
      "pisang-tanduk (0.021820730762556195%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [tanduk003.jpg]: \n",
      "[('n07753592', 'banana', 0.9293711), ('n01978455', 'rock_crab', 0.009973473)]\n",
      "\n",
      "\n",
      "With Transfer Learning [tanduk003.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-tanduk (99.99971389770508%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (0.00028856836706836475%)\n",
      "pisang-tanduk (99.99971389770508%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok009.jpg]: \n",
      "[('n07753592', 'banana', 0.99724257), ('n07718747', 'artichoke', 0.001915531)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok009.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (99.99998807907104%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (99.99998807907104%)\n",
      "pisang-tanduk (9.504068998467119e-06%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok002.jpg]: \n",
      "[('n07753592', 'banana', 0.83729273), ('n07714990', 'broccoli', 0.023880813)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok002.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "pisang-tanduk (1.7250719963612937e-06%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok007.jpg]: \n",
      "[('n07753592', 'banana', 0.8881245), ('n07717410', 'acorn_squash', 0.07438593)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok007.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (99.99827146530151%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (99.99827146530151%)\n",
      "pisang-tanduk (0.0017325397493550554%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [tanduk001.jpg]: \n",
      "[('n07684084', 'French_loaf', 0.066945456), ('n02321529', 'sea_cucumber', 0.06268961)]\n",
      "\n",
      "\n",
      "With Transfer Learning [tanduk001.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-tanduk (100.0%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (3.721278927365512e-10%)\n",
      "pisang-tanduk (100.0%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok014.jpg]: \n",
      "[('n07753592', 'banana', 0.84555036), ('n07760859', 'custard_apple', 0.08841096)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok014.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (99.99305009841919%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (99.99305009841919%)\n",
      "pisang-tanduk (0.006952045077923685%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok021.jpg]: \n",
      "[('n07716358', 'zucchini', 0.29164246), ('n07718472', 'cucumber', 0.084130384)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok021.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (99.99980926513672%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (99.99980926513672%)\n",
      "pisang-tanduk (0.00019638869162008632%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok017.jpg]: \n",
      "[('n07753592', 'banana', 0.9885358), ('n13133613', 'ear', 0.0061675785)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok017.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "pisang-tanduk (6.031204424772341e-07%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok005.jpg]: \n",
      "[('n07753592', 'banana', 0.7398142), ('n03461385', 'grocery_store', 0.22782113)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok005.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (99.99408721923828%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (99.99408721923828%)\n",
      "pisang-tanduk (0.005914664143347181%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok013.jpg]: \n",
      "[('n07753592', 'banana', 0.64761806), ('n07718747', 'artichoke', 0.088909715)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok013.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (99.97027516365051%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (99.97027516365051%)\n",
      "pisang-tanduk (0.029719839221797884%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok012.jpg]: \n",
      "[('n07753592', 'banana', 0.90954), ('n13133613', 'ear', 0.03717878)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok012.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (99.99998807907104%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (99.99998807907104%)\n",
      "pisang-tanduk (1.2415637229423737e-05%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok022.jpg]: \n",
      "[('n13133613', 'ear', 0.33394906), ('n07754684', 'jackfruit', 0.14382365)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok022.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-tanduk (99.9984622001648%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (0.0015406589227495715%)\n",
      "pisang-tanduk (99.9984622001648%)\n",
      "\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Transfer Learning Top-2 [kepok010.jpg]: \n",
      "[('n07754684', 'jackfruit', 0.48873183), ('n07753592', 'banana', 0.1798069)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok010.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "pisang-tanduk (1.3649805244431157e-09%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok004.jpg]: \n",
      "[('n07753592', 'banana', 0.40068734), ('n07753275', 'pineapple', 0.13428028)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok004.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "pisang-tanduk (2.765926510051031e-06%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok020.jpg]: \n",
      "[('n07753592', 'banana', 0.9886154), ('n07760859', 'custard_apple', 0.0020554317)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok020.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (100.0%)\n",
      "pisang-tanduk (4.228452310517383e-08%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [tanduk004.jpg]: \n",
      "[('n07753592', 'banana', 0.9968892), ('n07717410', 'acorn_squash', 0.0022411372)]\n",
      "\n",
      "\n",
      "With Transfer Learning [tanduk004.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-tanduk (100.0%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (3.522180103132655e-07%)\n",
      "pisang-tanduk (100.0%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok023.jpg]: \n",
      "[('n07753592', 'banana', 0.9505895), ('n07760859', 'custard_apple', 0.0121236155)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok023.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-kepok (99.99892711639404%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (99.99892711639404%)\n",
      "pisang-tanduk (0.0010713221854530275%)\n",
      "\n",
      "============================\n",
      "\n",
      "Without Transfer Learning Top-2 [kepok006.jpg]: \n",
      "[('n03785016', 'moped', 0.818446), ('n03791053', 'motor_scooter', 0.1427246)]\n",
      "\n",
      "\n",
      "With Transfer Learning [kepok006.jpg]: \n",
      "Top-1 (confidence)\n",
      "pisang-tanduk (59.974604845047%)\n",
      "\n",
      "Class (confidence)\n",
      "pisang-kepok (40.02540111541748%)\n",
      "pisang-tanduk (59.974604845047%)\n",
      "\n",
      "============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_path = 'pisang-test/'\n",
    "\n",
    "for directory in os.listdir(test_path):\n",
    "    \n",
    "    # Load image.\n",
    "    img_path = test_path+directory\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    preds = model.predict(x)\n",
    "    default_preds = default_model.predict(x)\n",
    "\n",
    "    # Printing results.\n",
    "\n",
    "    # Default 1000 classes (without transfer learning).\n",
    "    print(f\"Without Transfer Learning Top-2 [{directory}]: \\n{decode_predictions(default_preds, top=2)[0]}\\n\")\n",
    "\n",
    "    # Print transfer learning model top-1\n",
    "    confidence_array = preds[0]\n",
    "    index_max = np.argmax(confidence_array)\n",
    "\n",
    "    # Get KEY (category) by VALUE (index_max) in dictionary\n",
    "    # mydict = {'george':16,'amber':19}\n",
    "    # print(list(mydict.keys())[list(mydict.values()).index(16)]) # Example in one line.\n",
    "\n",
    "    category_names = category_dict.keys()\n",
    "    category_values = category_dict.values()\n",
    "    category_at_index = list(category_values).index(index_max)\n",
    "    category_max = list(category_names)[category_at_index]\n",
    "\n",
    "    print(f\"\\nWith Transfer Learning [{directory}]: \\nTop-1 (confidence)\\n{category_max} ({max(confidence_array)*100}%)\")\n",
    "\n",
    "    # Print transfer learning model all classes\n",
    "    print(\"\\nClass (confidence)\")\n",
    "\n",
    "    for category in category_dict:\n",
    "        category_index = category_dict[category]\n",
    "        value = confidence_array[category_index] * 100\n",
    "        print(f\"{category} ({value}%)\")\n",
    "\n",
    "    print(\"\\n============================\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catatan: Hasil yang lebih dulu di*print* adalah yang lebih dulu terbaca oleh ```os.listdir()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kepok008.jpg tanduk006.jpg kepok015.jpg kepok016.jpg kepok024.jpg kepok018.jpg kepok003.jpg kepok011.jpg tanduk007.jpg tanduk005.jpg tanduk002.jpg kepok001.jpg kepok019.jpg tanduk003.jpg kepok009.jpg kepok002.jpg kepok007.jpg tanduk001.jpg kepok014.jpg kepok021.jpg kepok017.jpg kepok005.jpg kepok013.jpg kepok012.jpg kepok022.jpg kepok010.jpg kepok004.jpg kepok020.jpg tanduk004.jpg kepok023.jpg kepok006.jpg "
     ]
    }
   ],
   "source": [
    "for directory in os.listdir(test_path):\n",
    "    print(directory, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selesai!\n",
    "\n",
    "Sesuai motivasi dibuatnya Keras sendiri \"*easy and fast prototyping*\", notebook ini dibuat generik. Dengan mengulangi langkah yang sama, misalnya, **mengumpulkan gambar berbagai jenis apel**, kita dapat mengklasifikasi jenis apel dengan belasan hingga puluhan gambar saja. (Tentunya apabila data yang dimiliki sedikit, kita harus lebih berinvestasi pada eksperimentasi beberapa variabel seperti jumlah layer yang di*freeze*, ukuran Dense layer, dan sebagainya.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
